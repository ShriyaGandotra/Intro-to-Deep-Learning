{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHEFd4QJ40H3",
        "outputId": "e495345b-6317-49df-f23a-430e180bf2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 3.3515, Train Accuracy: 0.1604, Val Loss: 14.4219, Val Accuracy: 0.1554\n",
            "Epoch 2/50, Train Loss: 2.4515, Train Accuracy: 0.1875, Val Loss: 12.8186, Val Accuracy: 0.1704\n",
            "Epoch 3/50, Train Loss: 2.2409, Train Accuracy: 0.1926, Val Loss: 15.4213, Val Accuracy: 0.1978\n",
            "Epoch 4/50, Train Loss: 2.4782, Train Accuracy: 0.2200, Val Loss: 12.0950, Val Accuracy: 0.1864\n",
            "Epoch 5/50, Train Loss: 2.2742, Train Accuracy: 0.2053, Val Loss: 15.8559, Val Accuracy: 0.2388\n",
            "Epoch 6/50, Train Loss: 2.3918, Train Accuracy: 0.2073, Val Loss: 15.6087, Val Accuracy: 0.2598\n",
            "Epoch 7/50, Train Loss: 2.4950, Train Accuracy: 0.2268, Val Loss: 15.4959, Val Accuracy: 0.2244\n",
            "Epoch 8/50, Train Loss: 2.5180, Train Accuracy: 0.2284, Val Loss: 12.2621, Val Accuracy: 0.2098\n",
            "Epoch 9/50, Train Loss: 2.4192, Train Accuracy: 0.2312, Val Loss: 14.8061, Val Accuracy: 0.2705\n",
            "Epoch 10/50, Train Loss: 2.5100, Train Accuracy: 0.2525, Val Loss: 14.8362, Val Accuracy: 0.2287\n",
            "Epoch 11/50, Train Loss: 2.4441, Train Accuracy: 0.2481, Val Loss: 14.0163, Val Accuracy: 0.2407\n",
            "Epoch 12/50, Train Loss: 2.3971, Train Accuracy: 0.2523, Val Loss: 14.0386, Val Accuracy: 0.2460\n",
            "Epoch 13/50, Train Loss: 2.3140, Train Accuracy: 0.2717, Val Loss: 14.1933, Val Accuracy: 0.2943\n",
            "Epoch 14/50, Train Loss: 2.2268, Train Accuracy: 0.3096, Val Loss: 15.9340, Val Accuracy: 0.3585\n",
            "Epoch 15/50, Train Loss: 2.2673, Train Accuracy: 0.3291, Val Loss: 13.3548, Val Accuracy: 0.3418\n",
            "Epoch 16/50, Train Loss: 2.1949, Train Accuracy: 0.3286, Val Loss: 13.9763, Val Accuracy: 0.3708\n",
            "Epoch 17/50, Train Loss: 2.0924, Train Accuracy: 0.3576, Val Loss: 11.5150, Val Accuracy: 0.3534\n",
            "Epoch 18/50, Train Loss: 2.0266, Train Accuracy: 0.3772, Val Loss: 11.6281, Val Accuracy: 0.3771\n",
            "Epoch 19/50, Train Loss: 1.9762, Train Accuracy: 0.3761, Val Loss: 11.4410, Val Accuracy: 0.3910\n",
            "Epoch 20/50, Train Loss: 1.9381, Train Accuracy: 0.3674, Val Loss: 11.9656, Val Accuracy: 0.4071\n",
            "Epoch 21/50, Train Loss: 1.8963, Train Accuracy: 0.4057, Val Loss: 10.9081, Val Accuracy: 0.3878\n",
            "Epoch 22/50, Train Loss: 1.8799, Train Accuracy: 0.4184, Val Loss: 11.5983, Val Accuracy: 0.4531\n",
            "Epoch 23/50, Train Loss: 1.7835, Train Accuracy: 0.4149, Val Loss: 10.9901, Val Accuracy: 0.4548\n",
            "Epoch 24/50, Train Loss: 1.7658, Train Accuracy: 0.4326, Val Loss: 9.9359, Val Accuracy: 0.4438\n",
            "Epoch 25/50, Train Loss: 1.6610, Train Accuracy: 0.4629, Val Loss: 9.5394, Val Accuracy: 0.4734\n",
            "Epoch 26/50, Train Loss: 1.6095, Train Accuracy: 0.4689, Val Loss: 10.6447, Val Accuracy: 0.5776\n",
            "Epoch 27/50, Train Loss: 1.5721, Train Accuracy: 0.4898, Val Loss: 9.2315, Val Accuracy: 0.6004\n",
            "Epoch 28/50, Train Loss: 1.4316, Train Accuracy: 0.5201, Val Loss: 8.8963, Val Accuracy: 0.6143\n",
            "Epoch 29/50, Train Loss: 1.4277, Train Accuracy: 0.5261, Val Loss: 9.0707, Val Accuracy: 0.6639\n",
            "Epoch 30/50, Train Loss: 1.3298, Train Accuracy: 0.5572, Val Loss: 8.1521, Val Accuracy: 0.6923\n",
            "Epoch 31/50, Train Loss: 1.2381, Train Accuracy: 0.5969, Val Loss: 7.4632, Val Accuracy: 0.7438\n",
            "Epoch 32/50, Train Loss: 1.1764, Train Accuracy: 0.6411, Val Loss: 7.0843, Val Accuracy: 0.7583\n",
            "Epoch 33/50, Train Loss: 1.1108, Train Accuracy: 0.6739, Val Loss: 6.4141, Val Accuracy: 0.7773\n",
            "Epoch 34/50, Train Loss: 1.0068, Train Accuracy: 0.6735, Val Loss: 6.7426, Val Accuracy: 0.8152\n",
            "Epoch 35/50, Train Loss: 0.9387, Train Accuracy: 0.7169, Val Loss: 5.6223, Val Accuracy: 0.8428\n",
            "Epoch 36/50, Train Loss: 0.8944, Train Accuracy: 0.7368, Val Loss: 4.5897, Val Accuracy: 0.8698\n",
            "Epoch 37/50, Train Loss: 0.7773, Train Accuracy: 0.7809, Val Loss: 6.1709, Val Accuracy: 0.8348\n",
            "Epoch 38/50, Train Loss: 0.7397, Train Accuracy: 0.8117, Val Loss: 4.3360, Val Accuracy: 0.9102\n",
            "Epoch 39/50, Train Loss: 0.6652, Train Accuracy: 0.8432, Val Loss: 3.6911, Val Accuracy: 0.8355\n",
            "Epoch 40/50, Train Loss: 0.5608, Train Accuracy: 0.8700, Val Loss: 3.0768, Val Accuracy: 0.9395\n",
            "Epoch 41/50, Train Loss: 0.5417, Train Accuracy: 0.8496, Val Loss: 2.8988, Val Accuracy: 0.9368\n",
            "Epoch 42/50, Train Loss: 0.4654, Train Accuracy: 0.9131, Val Loss: 3.2952, Val Accuracy: 0.9173\n",
            "Epoch 43/50, Train Loss: 0.4555, Train Accuracy: 0.9126, Val Loss: 2.1700, Val Accuracy: 0.9416\n",
            "Epoch 44/50, Train Loss: 0.3861, Train Accuracy: 0.9356, Val Loss: 2.0281, Val Accuracy: 0.9466\n",
            "Epoch 45/50, Train Loss: 0.3653, Train Accuracy: 0.9183, Val Loss: 1.9270, Val Accuracy: 0.9604\n",
            "Epoch 46/50, Train Loss: 0.3193, Train Accuracy: 0.9475, Val Loss: 1.6579, Val Accuracy: 0.9640\n",
            "Epoch 47/50, Train Loss: 0.3014, Train Accuracy: 0.9634, Val Loss: 1.6521, Val Accuracy: 0.9667\n",
            "Epoch 48/50, Train Loss: 0.2844, Train Accuracy: 0.9485, Val Loss: 1.5242, Val Accuracy: 0.9513\n",
            "Epoch 49/50, Train Loss: 0.2396, Train Accuracy: 0.9596, Val Loss: 1.3514, Val Accuracy: 0.9719\n",
            "Epoch 50/50, Train Loss: 0.2116, Train Accuracy: 0.9710, Val Loss: 1.4592, Val Accuracy: 0.9521\n",
            "Translated: le bébé\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "english_to_french = [\n",
        "\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    tokens = [token for sentence in sentences for token in sentence]\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    vocab.update({token: i+3 for i, token in enumerate(set(tokens))})\n",
        "    return vocab\n",
        "\n",
        "# Custom dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
        "        self.src_sentences = [[src_vocab[token] for token in ['<sos>'] + sentence + ['<eos>']] for sentence in src_sentences]\n",
        "        self.tgt_sentences = [[tgt_vocab[token] for token in ['<sos>'] + sentence + ['<eos>']] for sentence in tgt_sentences]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_sentence = self.src_sentences[idx]\n",
        "        tgt_sentence = self.tgt_sentences[idx]\n",
        "        return torch.tensor(src_sentence, dtype=torch.long), torch.tensor(tgt_sentence, dtype=torch.long)\n",
        "\n",
        "# Tokenize and build vocab\n",
        "tokenized_en = [tokenize(en) for en, fr in english_to_french]\n",
        "tokenized_fr = [tokenize(fr) for en, fr in english_to_french]\n",
        "en_vocab = build_vocab(tokenized_en)\n",
        "fr_vocab = build_vocab(tokenized_fr)\n",
        "rev_fr_vocab = {v: k for k, v in fr_vocab.items()}\n",
        "\n",
        "# Assuming the division between training and validation data has been made\n",
        "# For demonstration, using the full dataset for both training and validation\n",
        "train_dataset = TranslationDataset(tokenized_en, tokenized_fr, en_vocab, fr_vocab)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Encoder definition\n",
        "class EncoderGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_layers, dropout):\n",
        "        super(EncoderGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(self.n_layers, 1, self.hidden_size)\n",
        "\n",
        "# Decoder definition\n",
        "class DecoderGRU(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, n_layers, dropout):\n",
        "        super(DecoderGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(self.n_layers, 1, self.hidden_size)\n",
        "\n",
        "# Initialize models, optimizers, and loss function\n",
        "enc = EncoderGRU(len(en_vocab), 256, 2, 0.5)\n",
        "dec = DecoderGRU(len(fr_vocab), 256, 2, 0.5)\n",
        "enc_optimizer = optim.SGD(enc.parameters(), lr=0.01)\n",
        "dec_optimizer = optim.SGD(dec.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=50):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "    correct = 0  # To calculate accuracy\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[fr_vocab['<sos>']]])\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "        if decoder_input.item() == target_tensor[di].item():\n",
        "            correct += 1\n",
        "\n",
        "        if decoder_input.item() == fr_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    accuracy = correct / target_length  # Calculate accuracy\n",
        "\n",
        "    return loss.item() / target_length, accuracy\n",
        "\n",
        "# Validation function\n",
        "def validate(encoder, decoder, dataloader, criterion, max_length=50):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.squeeze(0), tgt.squeeze(0)\n",
        "            loss, accuracy = evaluate(src, tgt, encoder, decoder, criterion, max_length)\n",
        "            total_loss += loss\n",
        "            total_accuracy += accuracy\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_accuracy = total_accuracy / len(dataloader)\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "# Evaluate function\n",
        "def evaluate(src_tensor, tgt_tensor, encoder, decoder, criterion, max_length=50):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    input_length = src_tensor.size(0)\n",
        "    target_length = tgt_tensor.size(0)\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(src_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[fr_vocab['<sos>']]])\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        if topi.item() == tgt_tensor[di].item():\n",
        "            correct += 1\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        loss += criterion(decoder_output, tgt_tensor[di].unsqueeze(0))\n",
        "        if decoder_input.item() == fr_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    accuracy = correct / target_length\n",
        "    return loss.item(), accuracy\n",
        "\n",
        "def train_loop(num_epochs, train_dataloader, val_dataloader, encoder, decoder, enc_optimizer, dec_optimizer, criterion):\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0\n",
        "        total_train_accuracy = 0\n",
        "\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        for src, tgt in train_dataloader:\n",
        "            src, tgt = src.squeeze(0), tgt.squeeze(0)\n",
        "            loss, accuracy = train(src, tgt, encoder, decoder, enc_optimizer, dec_optimizer, criterion)\n",
        "            total_train_loss += loss\n",
        "            total_train_accuracy += accuracy\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "\n",
        "        # Validation phase with loss and accuracy\n",
        "        avg_val_loss, avg_val_accuracy = validate(encoder, decoder, val_dataloader, criterion)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_accuracy:.4f}')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train_loop(50, train_dataloader, val_dataloader, enc, dec, enc_optimizer, dec_optimizer, criterion)\n",
        "\n",
        "# Translation function\n",
        "def translate(sentence, encoder, decoder, src_vocab, tgt_vocab, rev_tgt_vocab, max_length=50):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = [src_vocab[token] for token in tokenize(sentence)]\n",
        "        input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        input_length = input_tensor.size(0)\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[tgt_vocab['<sos>']]])\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "\n",
        "            if topi.item() == tgt_vocab['<eos>']:\n",
        "                break  # Only break if <EOS> is genuinely predicted\n",
        "            else:\n",
        "                decoded_words.append(rev_tgt_vocab[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return ' '.join(decoded_words)\n",
        "\n",
        "# Example translation\n",
        "example_sentence = \"The baby cries\"\n",
        "translated_sentence = translate(example_sentence, enc, dec, en_vocab, fr_vocab, rev_fr_vocab)\n",
        "print(f'Translated: {translated_sentence}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Simple tokenization and vocab building\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    tokens = [token for sentence in sentences for token in tokenize(sentence)]\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    vocab.update({token: i+3 for i, token in enumerate(sorted(set(tokens)))})\n",
        "    return vocab\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
        "        self.src_sentences = [[src_vocab[token] for token in ['<sos>'] + tokenize(sentence) + ['<eos>']] for sentence in src_sentences]\n",
        "        self.tgt_sentences = [[tgt_vocab[token] for token in ['<sos>'] + tokenize(sentence) + ['<eos>']] for sentence in tgt_sentences]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.src_sentences[idx]), torch.tensor(self.tgt_sentences[idx])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=0, batch_first=True)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "english_to_french = [\n",
        "\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
        "\n",
        "]\n",
        "\n",
        "english_sentences, french_sentences = zip(*english_to_french)\n",
        "\n",
        "src_vocab = build_vocab(english_sentences)\n",
        "tgt_vocab = build_vocab(french_sentences)\n",
        "\n",
        "train_dataset = TranslationDataset(english_sentences, french_sentences, src_vocab, tgt_vocab)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden = hidden.repeat(src_len, 1, 1).permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, num_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU(hid_dim + emb_dim, hid_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # Ensure input is [batch_size, 1] for embedding\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        a = self.attention(hidden[-1], encoder_outputs)  # Ensure attention uses last hidden state\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)  # Weighted encoder outputs as context\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)  # Concatenate embedded input and context\n",
        "\n",
        "        output, hidden = self.gru(rnn_input, hidden)  # GRU forward pass\n",
        "\n",
        "        # Directly concatenate the output and weighted context for the fully connected layer\n",
        "        prediction = self.fc_out(torch.cat((output.squeeze(1), weighted.squeeze(1)), dim=1))\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(tgt_vocab)\n",
        "ENC_EMB_DIM = DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = DEC_DROPOUT = 0.5\n",
        "\n",
        "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attention = Attention(HID_DIM).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attention).to(device)\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()))\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "\n",
        "def train_and_evaluate(encoder, decoder, train_dataloader, val_dataloader, optimizer, criterion, device, n_epochs=10):\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Reset metrics at the start of each epoch\n",
        "        training_loss, training_accuracy = 0.0, 0.0\n",
        "        correct_tokens, total_tokens = 0, 0\n",
        "\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "\n",
        "        for src, tgt in train_dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            encoder_outputs, hidden = encoder(src)\n",
        "\n",
        "            # Assuming the first token provided to the decoder is <sos>\n",
        "            input = tgt[:, 0]\n",
        "            output_tokens = torch.zeros(tgt.size(0), tgt.size(1)-1, OUTPUT_DIM, device=device)\n",
        "\n",
        "            for t in range(1, tgt.size(1)):\n",
        "                output, hidden = decoder(input, hidden, encoder_outputs)\n",
        "                output_tokens[:, t-1, :] = output\n",
        "                top1 = output.argmax(1)\n",
        "                correct_tokens += (top1 == tgt[:, t]).sum().item()\n",
        "                total_tokens += tgt[:, t].numel()\n",
        "                input = top1  # Using greedy decoding for simplicity\n",
        "\n",
        "            output_dim = output_tokens.shape[-1]\n",
        "            output_tokens = output_tokens.contiguous().view(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_tokens, tgt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()\n",
        "\n",
        "        train_loss = training_loss / len(train_dataloader)\n",
        "        train_accuracy = correct_tokens / total_tokens\n",
        "\n",
        "        # Validation (Similar structure, calculate val_loss and val_accuracy)\n",
        "        val_loss, val_accuracy = evaluate(encoder, decoder, val_dataloader, criterion, device)\n",
        "\n",
        "\n",
        "        print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Training Acc: {train_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Acc: {val_accuracy:.4f}')\n",
        "\n",
        "def evaluate(encoder, decoder, dataloader, criterion, device):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    epoch_loss = 0\n",
        "    correct_tokens, total_tokens = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            encoder_outputs, hidden = encoder(src)\n",
        "            output_tokens = torch.zeros(tgt.size(0), tgt.size(1)-1, OUTPUT_DIM, device=device)\n",
        "            input = tgt[:, 0]\n",
        "\n",
        "            for t in range(1, tgt.size(1)):\n",
        "                output, hidden = decoder(input, hidden, encoder_outputs)\n",
        "                output_tokens[:, t-1, :] = output\n",
        "                input = output.argmax(1)\n",
        "                correct_tokens += (input == tgt[:, t]).sum().item()\n",
        "                total_tokens += input.shape[0]\n",
        "\n",
        "            output_dim = output_tokens.shape[-1]\n",
        "            output_tokens = output_tokens.contiguous().view(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_tokens, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    val_loss = epoch_loss / len(dataloader)\n",
        "    val_accuracy = correct_tokens / total_tokens\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "# Assuming all other components (model definition, optimizer setup) are the same\n",
        "train_and_evaluate(encoder, decoder, train_dataloader, val_dataloader, optimizer, criterion, device, n_epochs=25)\n",
        "\n",
        "def translate_sentence(sentence, src_vocab, tgt_vocab, encoder, decoder, device, max_length=50):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    tokens = ['<sos>'] + tokenize(sentence) + ['<eos>']\n",
        "    src_indexes = [src_vocab[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = encoder(src_tensor)\n",
        "\n",
        "    tgt_indexes = [tgt_vocab['<sos>']]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        tgt_tensor = torch.LongTensor([tgt_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = decoder(tgt_tensor, hidden, encoder_outputs)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        tgt_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == tgt_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    tgt_tokens = [list(tgt_vocab.keys())[list(tgt_vocab.values()).index(i)] for i in tgt_indexes]\n",
        "\n",
        "    return tgt_tokens[1:-1]  # Remove <sos> and <eos> tokens\n",
        "\n",
        "# Translate a single sentence\n",
        "example_sentence = \"The baby cries\"\n",
        "print(f'Original in English: {example_sentence}')\n",
        "translation = translate_sentence(example_sentence, src_vocab, tgt_vocab, encoder, decoder, device)\n",
        "print(f'Translated to French: {\" \".join(translation)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4GC7T2oXPeD",
        "outputId": "5599585d-da60-4ada-b087-d1fabbb8d018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 4.5600, Training Acc: 0.1900, Validation Loss: 4.8737, Validation Acc: 0.1770\n",
            "Epoch: 2, Training Loss: 3.6869, Training Acc: 0.2703, Validation Loss: 5.0579, Validation Acc: 0.1925\n",
            "Epoch: 3, Training Loss: 3.1372, Training Acc: 0.3178, Validation Loss: 5.4097, Validation Acc: 0.1836\n",
            "Epoch: 4, Training Loss: 2.5800, Training Acc: 0.3315, Validation Loss: 5.8698, Validation Acc: 0.1704\n",
            "Epoch: 5, Training Loss: 2.1575, Training Acc: 0.3834, Validation Loss: 6.2447, Validation Acc: 0.1792\n",
            "Epoch: 6, Training Loss: 1.7035, Training Acc: 0.4384, Validation Loss: 6.6514, Validation Acc: 0.1792\n",
            "Epoch: 7, Training Loss: 1.3322, Training Acc: 0.5329, Validation Loss: 6.7263, Validation Acc: 0.1792\n",
            "Epoch: 8, Training Loss: 0.9202, Training Acc: 0.6160, Validation Loss: 7.3957, Validation Acc: 0.1726\n",
            "Epoch: 9, Training Loss: 0.8105, Training Acc: 0.6574, Validation Loss: 7.6785, Validation Acc: 0.1615\n",
            "Epoch: 10, Training Loss: 0.7113, Training Acc: 0.6822, Validation Loss: 8.0114, Validation Acc: 0.1593\n",
            "Epoch: 11, Training Loss: 0.5783, Training Acc: 0.7324, Validation Loss: 8.0674, Validation Acc: 0.1637\n",
            "Epoch: 12, Training Loss: 0.4805, Training Acc: 0.7422, Validation Loss: 8.3602, Validation Acc: 0.1504\n",
            "Epoch: 13, Training Loss: 0.3809, Training Acc: 0.7765, Validation Loss: 8.3839, Validation Acc: 0.1327\n",
            "Epoch: 14, Training Loss: 0.2782, Training Acc: 0.7849, Validation Loss: 8.6259, Validation Acc: 0.1659\n",
            "Epoch: 15, Training Loss: 0.2775, Training Acc: 0.8065, Validation Loss: 8.6585, Validation Acc: 0.1504\n",
            "Epoch: 16, Training Loss: 0.1705, Training Acc: 0.8285, Validation Loss: 8.8111, Validation Acc: 0.1482\n",
            "Epoch: 17, Training Loss: 0.1269, Training Acc: 0.8378, Validation Loss: 8.9721, Validation Acc: 0.1504\n",
            "Epoch: 18, Training Loss: 0.1208, Training Acc: 0.8337, Validation Loss: 9.1209, Validation Acc: 0.1504\n",
            "Epoch: 19, Training Loss: 0.0875, Training Acc: 0.8730, Validation Loss: 9.0970, Validation Acc: 0.1482\n",
            "Epoch: 20, Training Loss: 0.0801, Training Acc: 0.8527, Validation Loss: 9.2328, Validation Acc: 0.1438\n",
            "Epoch: 21, Training Loss: 0.0672, Training Acc: 0.8569, Validation Loss: 9.3595, Validation Acc: 0.1460\n",
            "Epoch: 22, Training Loss: 0.0518, Training Acc: 0.8772, Validation Loss: 9.4602, Validation Acc: 0.1416\n",
            "Epoch: 23, Training Loss: 0.0618, Training Acc: 0.8613, Validation Loss: 9.5134, Validation Acc: 0.1372\n",
            "Epoch: 24, Training Loss: 0.0483, Training Acc: 0.8728, Validation Loss: 9.5930, Validation Acc: 0.1416\n",
            "Epoch: 25, Training Loss: 0.0381, Training Acc: 0.8762, Validation Loss: 9.6940, Validation Acc: 0.1394\n",
            "Original in English: The baby cries\n",
            "Translated to French: le bébé pleure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Simple tokenization and vocab building\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    tokens = [token for sentence in sentences for token in tokenize(sentence)]\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    vocab.update({token: i+3 for i, token in enumerate(sorted(set(tokens)))})\n",
        "    return vocab\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
        "        self.src_sentences = [[src_vocab[token] for token in ['<sos>'] + tokenize(sentence) + ['<eos>']] for sentence in src_sentences]\n",
        "        self.tgt_sentences = [[tgt_vocab[token] for token in ['<sos>'] + tokenize(sentence) + ['<eos>']] for sentence in tgt_sentences]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.tgt_sentences[idx]), torch.tensor(self.src_sentences[idx])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    tgt_batch, src_batch = zip(*batch)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=0, batch_first=True)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    return tgt_batch, src_batch\n",
        "\n",
        "english_to_french = [\n",
        "\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
        "\n",
        "]\n",
        "\n",
        "french_to_english = [(french, english) for english, french in english_to_french]\n",
        "\n",
        "french_sentences, english_sentences = zip(*french_to_english)\n",
        "\n",
        "src_vocab = build_vocab(french_sentences)\n",
        "tgt_vocab = build_vocab(english_sentences)\n",
        "\n",
        "train_dataset = TranslationDataset(french_sentences, english_sentences, src_vocab, tgt_vocab)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Define validation dataset and dataloader\n",
        "val_dataset = TranslationDataset(french_sentences[:10], english_sentences[:10], src_vocab, tgt_vocab)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Define model parameters\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(tgt_vocab)\n",
        "ENC_EMB_DIM = DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = DEC_DROPOUT = 0.5\n",
        "\n",
        "# Define Encoder class\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "# Define Attention class\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden = hidden.repeat(src_len, 1, 1).permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "# Define Decoder class\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, num_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU(hid_dim + emb_dim, hid_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # Ensure input is [batch_size, 1] for embedding\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        a = self.attention(hidden[-1], encoder_outputs)  # Ensure attention uses last hidden state\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)  # Weighted encoder outputs as context\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)  # Concatenate embedded input and context\n",
        "\n",
        "        output, hidden = self.gru(rnn_input, hidden)  # GRU forward pass\n",
        "\n",
        "        # Directly concatenate the output and weighted context for the fully connected layer\n",
        "        prediction = self.fc_out(torch.cat((output.squeeze(1), weighted.squeeze(1)), dim=1))\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "# Initialize model components\n",
        "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attention = Attention(HID_DIM).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attention).to(device)\n",
        "\n",
        "# Initialize optimizer and criterion\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()))\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "def train_and_evaluate(encoder, decoder, train_dataloader, val_dataloader, optimizer, criterion, device, n_epochs=10):\n",
        "    for epoch in range(n_epochs):\n",
        "        # Reset metrics at the start of each epoch\n",
        "        training_loss, training_accuracy = 0.0, 0.0\n",
        "        correct_tokens, total_tokens = 0, 0\n",
        "\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "\n",
        "        for tgt, src in train_dataloader:\n",
        "            tgt, src = tgt.to(device), src.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            encoder_outputs, hidden = encoder(src)\n",
        "\n",
        "            # Assuming the first token provided to the decoder is <sos>\n",
        "            input = tgt[:, 0]\n",
        "            output_tokens = torch.zeros(tgt.size(0), tgt.size(1)-1, OUTPUT_DIM, device=device)\n",
        "\n",
        "            for t in range(1, tgt.size(1)):\n",
        "                output, hidden = decoder(input, hidden, encoder_outputs)\n",
        "                output_tokens[:, t-1, :] = output\n",
        "                top1 = output.argmax(1)\n",
        "                correct_tokens += (top1 == tgt[:, t]).sum().item()\n",
        "                total_tokens += tgt[:, t].numel()\n",
        "                input = top1  # Using greedy decoding for simplicity\n",
        "\n",
        "            output_dim = output_tokens.shape[-1]\n",
        "            output_tokens = output_tokens.contiguous().view(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_tokens, tgt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()\n",
        "\n",
        "        train_loss = training_loss / len(train_dataloader)\n",
        "        train_accuracy = correct_tokens / total_tokens\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_accuracy = evaluate(encoder, decoder, val_dataloader, criterion, device)\n",
        "\n",
        "        print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Training Acc: {train_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Acc: {val_accuracy:.4f}')\n",
        "\n",
        "def evaluate(encoder, decoder, dataloader, criterion, device):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    epoch_loss = 0\n",
        "    correct_tokens, total_tokens = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tgt, src in dataloader:\n",
        "            tgt, src = tgt.to(device), src.to(device)\n",
        "\n",
        "            encoder_outputs, hidden = encoder(src)\n",
        "            output_tokens = torch.zeros(tgt.size(0), tgt.size(1)-1, OUTPUT_DIM, device=device)\n",
        "            input = tgt[:, 0]\n",
        "\n",
        "            for t in range(1, tgt.size(1)):\n",
        "                output, hidden = decoder(input, hidden, encoder_outputs)\n",
        "                output_tokens[:, t-1, :] = output\n",
        "                input = output.argmax(1)\n",
        "                correct_tokens += (input == tgt[:, t]).sum().item()\n",
        "                total_tokens += input.shape[0]\n",
        "\n",
        "            output_dim = output_tokens.shape[-1]\n",
        "            output_tokens = output_tokens.contiguous().view(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_tokens, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    val_loss = epoch_loss / len(dataloader)\n",
        "    val_accuracy = correct_tokens / total_tokens\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "# Train the model\n",
        "train_and_evaluate(encoder, decoder, train_dataloader, val_dataloader, optimizer, criterion, device, n_epochs=15)\n",
        "\n",
        "def translate_sentence(sentence, src_vocab, tgt_vocab, encoder, decoder, device, max_length=50):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    tokens = ['<sos>'] + tokenize(sentence) + ['<eos>']\n",
        "    src_indexes = [src_vocab[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = encoder(src_tensor)\n",
        "\n",
        "    tgt_indexes = [tgt_vocab['<sos>']]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        tgt_tensor = torch.LongTensor([tgt_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = decoder(tgt_tensor, hidden, encoder_outputs)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        tgt_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == tgt_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    tgt_tokens = [list(tgt_vocab.keys())[list(tgt_vocab.values()).index(i)] for i in tgt_indexes]\n",
        "\n",
        "    return tgt_tokens[1:-1]  # Remove <sos> and <eos> tokens\n",
        "\n",
        "# Translate a single sentence\n",
        "example_sentence = \"Le bébé pleure\"\n",
        "print(f'Original in French: {example_sentence}')\n",
        "translation = translate_sentence(example_sentence, src_vocab, tgt_vocab, encoder, decoder, device)\n",
        "print(f'Translated to English: {\" \".join(translation)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCSuayBhm0nZ",
        "outputId": "89467c1a-66c6-4842-e8a5-7016c95537d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 4.2748, Training Acc: 0.2170, Validation Loss: 3.7927, Validation Acc: 0.1591\n",
            "Epoch: 2, Training Loss: 3.4622, Training Acc: 0.3170, Validation Loss: 2.5371, Validation Acc: 0.3636\n",
            "Epoch: 3, Training Loss: 2.8166, Training Acc: 0.3675, Validation Loss: 2.1813, Validation Acc: 0.4545\n",
            "Epoch: 4, Training Loss: 2.2627, Training Acc: 0.4298, Validation Loss: 1.2560, Validation Acc: 0.7273\n",
            "Epoch: 5, Training Loss: 1.8340, Training Acc: 0.4710, Validation Loss: 0.8384, Validation Acc: 0.8409\n",
            "Epoch: 6, Training Loss: 1.3442, Training Acc: 0.5702, Validation Loss: 0.5065, Validation Acc: 0.8864\n",
            "Epoch: 7, Training Loss: 0.8681, Training Acc: 0.6824, Validation Loss: 0.4394, Validation Acc: 0.8864\n",
            "Epoch: 8, Training Loss: 0.6033, Training Acc: 0.7564, Validation Loss: 0.1562, Validation Acc: 0.9545\n",
            "Epoch: 9, Training Loss: 0.4434, Training Acc: 0.7915, Validation Loss: 0.1530, Validation Acc: 0.9545\n",
            "Epoch: 10, Training Loss: 0.2800, Training Acc: 0.8458, Validation Loss: 0.0614, Validation Acc: 0.9773\n",
            "Epoch: 11, Training Loss: 0.1729, Training Acc: 0.8798, Validation Loss: 0.0372, Validation Acc: 0.9773\n",
            "Epoch: 12, Training Loss: 0.1284, Training Acc: 0.8747, Validation Loss: 0.0545, Validation Acc: 0.9545\n",
            "Epoch: 13, Training Loss: 0.0840, Training Acc: 0.9052, Validation Loss: 0.0166, Validation Acc: 0.9773\n",
            "Epoch: 14, Training Loss: 0.0693, Training Acc: 0.8879, Validation Loss: 0.0139, Validation Acc: 0.9773\n",
            "Epoch: 15, Training Loss: 0.1192, Training Acc: 0.8929, Validation Loss: 0.0134, Validation Acc: 0.9773\n",
            "Original in French: Le bébé pleure\n",
            "Translated to English: the baby cries\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}